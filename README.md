# 知乎回答导出

## 食用前声明

使用本工具需要相当的计算机基础。本人不提供任何除本文档外的无偿使用帮助，如果确有需要，可以通过我的GitHub主页中的邮箱联系我，付费教学或协助导出。

## 使用

### 第一步

代码执行位置：**浏览器开发者工具Console中**

打开个人主页的“回答”标签页，如我的地址为：https://www.zhihu.com/people/yxzlwz/answers

打开后此页面后，启动开发者工具，将代码目录下的`getAllAnswers.js`文件的内容复制Console中，然后回车执行。

该脚本会逐页访问你的所有回答，并导出一份包含问题标题和回答URL的`zhihu_data.json`。将该文件保存到项目根目录。

小提示：执行脚本前可根据自己网速情况设置`SleepSecond`参数，网速较慢或不稳定者建议设置>10，鉴于知乎API性能问题不建议设置<5。

### 第二步

（请自行安装依赖：`pip install selenium beautifulsoup4`，同时配置好Chrome Driver，可参考[这篇文章]()）

修改`getAnswer.py`中的参数：

- 必填项为`_cookies`，你需要在登录后访问任意知乎界面，从Network选项卡中找到时间最早的请求，并将请求头中的`Cookie`字段的值完整复制到此处。
- `use_optimize`选项为是否启用优化。启用后脚本会处理一些已知的MarkDown转换过程中可能导致的问题，但也有可能导致部分MarkDown内容的丢失。
- `sleep_seconds`为两次请求之间的等待时间。根据本人测试，连续请求逾千条回答，4s可保证账号和IP安全。

程序会缓存请求到的HTML文件，这意味着你可以在一次运行后再调整是否启用优化，而不必再漫长等待从知乎请求数据。

确认无误后运行 `python getAnswer.py`。

## 背景

知乎于2024年5月开始限制未登录用户查看完整内容、禁止除百度外的搜索引擎抓取内容。本人无法忍受个人使用的平台做出这样的改动，遂决定退出知乎。

> 发布于 2024-05-28 20:48・IP 属地山东
>
> 如果知乎一味进行这次未登录禁止查看、限制搜索引擎抓取
>
> 我将在完成我过去所有创作内容存档后退出知乎，这个时间最长不超过一个月
>
> 立贴为据

（链接：https://www.zhihu.com/question/532694537/answer/3512999300）

然而，当我希望导出回答时，却发现最近知乎对爬虫的限制严格到令人发指，我没有找到任何开源的可用实现。基于此情况，我编写了这些脚本，可以帮助像我一样不愿意继续与破坏互联网环境者狼狈为奸的前知乎用户导出自己的数据。

## 联系方式

邮箱：yxzlwz@gmail.com
